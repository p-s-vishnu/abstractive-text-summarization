{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive-text-summ.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/p-s-vishnu/cf8e88d4db99162461218bdaa58c083e/abstractive-text-summ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_FILznqy7Lg",
        "colab_type": "text"
      },
      "source": [
        "Abstractive Text Summarization\n",
        "===\n",
        "This notebook is an in-progress implementation/experiment of the [Abstractive Text Summarization using Sequence-to-sequence RNNs and\n",
        "Beyond](https://arxiv.org/abs/1602.06023) paper.\n",
        "\n",
        "Current Features\n",
        "---\n",
        "* model architecture supports LSTM & GRU (biLSTM-to-uniLSTM or biGRU-to-uniGRU)\n",
        "* implements batch data processing \n",
        "* implements attention mechanism ([Bahdanau et al.](https://arxiv.org/abs/1409.0473) & [Luong et al.(global dot)](https://arxiv.org/abs/1508.04025))\n",
        "* implements [scheduled sampling (teacher forcing)](https://arxiv.org/abs/1506.03099)\n",
        "* implements [tied embeddings](https://arxiv.org/pdf/1608.05859.pdf)\n",
        "* initializes encoder-decoder with pretrained vectors (glove.6B.200d)\n",
        "* implements custom training callbacks (tensorboard visualization for PyTorch, save best model & log checkpoint)\n",
        "* implements attention plots\n",
        "\n",
        "\n",
        "To-Do\n",
        "---\n",
        "* Implement additional linguistic features embeddings  \n",
        "* Implement generator-pointer switch and replace unknown words by selecting source token with the highest attention score.\n",
        "* Implement large vocabulary trick \n",
        "* Implement sentence level attention \n",
        "* Implement beam search during inference\n",
        "* implement rouge evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdpZPOry7Lj",
        "colab_type": "text"
      },
      "source": [
        "Requirements\n",
        "---\n",
        "\n",
        "1. Create conda environment \n",
        "\n",
        "`conda env create -f environment.yml`  --gpu\n",
        "\n",
        "`conda env create -f environment-cpu.yml`  --cpu\n",
        "\n",
        "2. Install dependencies (PyTorch, Fastai, TorchText, Tensorboard etc) via:\n",
        "\n",
        "`pip install -r requirements.txt`\n",
        "\n",
        "3. Download `spacy` english module\n",
        "\n",
        "`python -m spacy download en`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQ0mP_iy7Lm",
        "colab_type": "text"
      },
      "source": [
        "Dataset\n",
        "--\n",
        "\n",
        "The dataset used is a subset of the gigaword dataset and can be found [here](https://drive.google.com/file/d/0B6N7tANPyVeBNmlSX19Ld2xDU1E/view?usp=sharing).\n",
        "\n",
        "It contains 3,803,955 parallel source & target examples for training and 189,649 examples for validation.\n",
        "\n",
        "After downloading, we create article-title pairs, save in tabular datset format (.csv) and extract a sample subset (80,000 for training & 20,000 for validation). This data preparation can be found [here](/data-preparation.ipynb).\n",
        "\n",
        "An example article-title pair looks like this:\n",
        "\n",
        "`article: the algerian cabinet chaired by president abdelaziz bouteflika on sunday adopted the #### finance bill predicated on an oil price of ## dollars a barrel and a growth rate of #.# percent , it was announced here .`\n",
        "\n",
        "`title: algeria adopts #### finance bill with oil put at ## dollars a barrel`\n",
        "\n",
        "\n",
        "Training on the complete dataset (3M) would take a really long time. So in order to train and experiment faster we use our sample subset of 80,000 in this tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzU_Y3J4y7Lo",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giQMjV6j7q_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/alesee/abstractive-text-summarization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od5qiU_77vWm",
        "colab_type": "code",
        "outputId": "fc011206-bd1a-4e4b-ff09-98e5170d14d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd abstractive-text-summarization/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/abstractive-text-summarization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUPmpGGt72Rw",
        "colab_type": "code",
        "outputId": "c3d25d86-b757-4d10-ea3f-7d7b2a36071e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " abstractive-text-summ.ipynb   environment.yml                README.md\n",
            " \u001b[0m\u001b[01;34mdata\u001b[0m/                         \u001b[01;34mimgs\u001b[0m/                          requirements.txt\n",
            " data-preparation.ipynb        launch-tensorboard_viz.ipynb\n",
            " environment-cpu.yml          \u001b[01;34m'py scripts'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35AVhk9K8DKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJLcX7o5y7Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoQHNJyay7Ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c6d9adc8-35c3-41dc-bbf4-85f85595ab65"
      },
      "source": [
        "#declare the directory path to dataset  \n",
        "DATA_PATH = 'data/'\n",
        "SAMPLE_DATA_PATH = f'{DATA_PATH}sample_data/'\n",
        "PROCESSED_DATA_PATH = f'{DATA_PATH}processed_data/'\n",
        "\n",
        "#Enable GPU training \n",
        "import torch\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "print('USE_GPU={}'.format(USE_GPU))\n",
        "if USE_GPU:\n",
        "    print('current_device={}'.format(torch.cuda.current_device()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USE_GPU=True\n",
            "current_device=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ovyzBSSSy7L0",
        "colab_type": "text"
      },
      "source": [
        "## 1. Process dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "RfoSRtJDy7L1",
        "colab_type": "text"
      },
      "source": [
        "In order to train, we performed common processing steps on the dataset such as:\n",
        "\n",
        "* Loading dataset\n",
        "* Preprocessing dataset (tokenizing, appending begining-of-sentence and end-of-sentence tokens, truncating, etc)\n",
        "* Building a vocabulary\n",
        "* Creating dataset iterators\n",
        "* Batching, padding, and numericalizing. \n",
        "\n",
        "To process the dataset, we use the [torchtext](https://github.com/pytorch/text) library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "dnED98kqy7L2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data, vocab from torchtext \n",
        "from torchtext import data, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "kQaqPg5uy7L5",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Load & define preprocessing pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "KA8JqtZsy7L6",
        "colab_type": "text"
      },
      "source": [
        "To pre-process our data, we declare a `Field` class, and pass additional pre-processing arguments ( ex. tokenize with the `spacy` tokenizer, `lower` and append an `end-of-sentence` token to every example )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "wGHoomkiy7L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = data.get_tokenizer('spacy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "Nlv_mbmqy7L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize=tokenizer, lower=True, eos_token='_eos_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "veauLMbIy7MB",
        "colab_type": "text"
      },
      "source": [
        "Next, we load our training & validation tabular dataset using `data.TabularDataset.splits` which applies the defined preprocessing pipeline and returns their respective `Dataset` objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "aSTcvzh_y7MC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b89788ba-ea4c-4439-c2d9-de0b7df04adb"
      },
      "source": [
        "%%time\n",
        "trn_data_fields = [(\"source\", TEXT),\n",
        "                   (\"target\", TEXT)]\n",
        "\n",
        "trn, vld = data.TabularDataset.splits(path=f'{SAMPLE_DATA_PATH}',\n",
        "                                     train='train_ds.csv', validation='valid_ds.csv',\n",
        "                                     format='csv', skip_header=True, fields=trn_data_fields)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40 s, sys: 318 ms, total: 40.3 s\n",
            "Wall time: 40.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "YF3z0TfJy7MH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "77c08d5e-4f3d-4607-d645-ad3260657810"
      },
      "source": [
        "# a sample of the preprocessed data\n",
        "print(trn[0].source, trn[0].target)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['jason', 'blake', 'of', 'the', 'islanders', 'will', 'miss', 'the', 'rest', 'of', 'the', 'season', 'so', 'he', 'can', 'be', 'with', 'his', 'wife', ',', 'who', 'has', 'thyroid', 'cancer', 'and', 'is', 'to', 'give', 'birth', 'april', '#', '.'] ['blake', 'missing', 'rest', 'of', 'season']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "q5lsd5Kcy7ML",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Build vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "dmvXvkiLy7MM",
        "colab_type": "text"
      },
      "source": [
        "Building a vocabulary simply means mapping each unique token in the corpus to an integer value, and storing as a dictionary ex `{'the': 2, 'brown':3, 'fox':4}`. \n",
        "\n",
        "In addition to building a vocabulary, we also use torchtext to load an embedding matrix for each token using the `glove.6B.200d` pretrained vector.\n",
        "\n",
        "We pass to `TEXT.build_vocab` our training dataset object `trn` and also the name of the pretrained vector we would like to use `glove.6B.200d`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "x7SP3CMVy7MM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9776ca56-375a-4157-8c47-cfe58e9f489a"
      },
      "source": [
        "%%time\n",
        "pre_trained_vector_type = 'glove.6B.200d' \n",
        "TEXT.build_vocab(trn, vectors=pre_trained_vector_type )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.75 s, sys: 325 ms, total: 2.07 s\n",
            "Wall time: 3.67 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "M1b3xy23y7MS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "3bf2292f-6463-49c5-e8cc-a04791af5b1d"
      },
      "source": [
        "#10 most frequent words in the vocab\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('#', 152957),\n",
              " ('the', 130459),\n",
              " ('.', 105054),\n",
              " (',', 85497),\n",
              " ('to', 83508),\n",
              " ('in', 78169),\n",
              " ('of', 77424),\n",
              " ('a', 71025),\n",
              " ('on', 43536),\n",
              " ('and', 42555)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "DXdFulguy7Ma",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Create dataset iterator, batch, pad, and numericalize. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "3OpNVVdBy7Mb",
        "colab_type": "text"
      },
      "source": [
        "Next, create a training & validation iterator object, numericalize (turn text to tensors), batch examples of similar lengths together, randomly shuffle the data and pad tensors using `data.BucketIterator.splits`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "MTfWtW6ky7Mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "pdGelYrTy7Me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4e6f269d-18ec-45ee-e7d0-cb56d76fec78"
      },
      "source": [
        "train_iter, val_iter = data.BucketIterator.splits(\n",
        "                        (trn, vld), batch_sizes=(batch_size, int(batch_size*1.6)),\n",
        "                        device=(0 if USE_GPU else -1), \n",
        "                        sort_key=lambda x: len(x.source),\n",
        "                        shuffle=True, sort_within_batch=False, repeat=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "3IjKoMKFy7Mh",
        "colab_type": "text"
      },
      "source": [
        "Next, we stick each article-title batch pair tensor into a tuple (article, title). To do this we create a custom helper class `BatchTuple`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RhBRTlvry7Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchTuple():\n",
        "    def __init__(self, dataset, x_var, y_var):\n",
        "        self.dataset, self.x_var, self.y_var = dataset, x_var, y_var\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for batch in self.dataset:\n",
        "            x = getattr(batch, self.x_var) \n",
        "            y = getattr(batch, self.y_var)                 \n",
        "            yield (x, y)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ogF43Zz_y7Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#returns tuple of article-title pair tensors\n",
        "train_iter_tuple = BatchTuple(train_iter, \"source\", \"target\")\n",
        "val_iter_tuple = BatchTuple(val_iter, \"source\", \"target\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "B_FI9Afsy7Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "789ba879-2120-4611-c35e-3d635fcb0828"
      },
      "source": [
        "#an example of a batched and padded article-title tensor pair\n",
        "next(iter(train_iter_tuple))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    4,  4772,  5404,  ...,    93,  1045,    10],\n",
              "         [   76,  7618, 26357,  ...,   480,   186,  1244],\n",
              "         [  519,    13,    22,  ...,   378,   188,     9],\n",
              "         ...,\n",
              "         [    1,     1,   403,  ...,     1,     1,     1],\n",
              "         [    1,     1,     5,  ...,     1,     1,     1],\n",
              "         [    1,     1,     2,  ...,     1,     1,     1]]),\n",
              " tensor([[ 2567,  7618,  5404,  ...,    93,  1045,  1244],\n",
              "         [ 2456,  1161, 26357,  ...,   480,   334,  1651],\n",
              "         [ 2452,  1350,    22,  ...,   378,  4687,   684],\n",
              "         ...,\n",
              "         [    1,     1,     1,  ...,     1,     1,     1],\n",
              "         [    1,     1,     1,  ...,     1,     1,     1],\n",
              "         [    1,     1,     1,  ...,     1,     1,     1]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "t739SN93y7M3",
        "colab_type": "text"
      },
      "source": [
        "### 1.4. Create ModelData "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "XKkup8Kiy7M3",
        "colab_type": "text"
      },
      "source": [
        "In order to use our batched dataset with the FastAI library, we create a `ModelData` object. \n",
        "\n",
        "`ModelData` simply sticks the training, validation (and test) dataset into a single object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "3OKhpAcCy7M5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import text module from fastai \n",
        "from fastai.text import *\n",
        "# from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPi2EsORVA5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelData():\n",
        "    \"\"\"Encapsulates DataLoaders and Datasets for training, validation, test. Base class for fastai *Data classes.\"\"\"\n",
        "    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n",
        "        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n",
        "\n",
        "    @classmethod\n",
        "    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n",
        "        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n",
        "        #if test_dl: test_dl = DataLoader(test_dl)\n",
        "        return cls(path, trn_dl, val_dl, test_dl)\n",
        "\n",
        "    @property\n",
        "    def is_reg(self): return self.trn_ds.is_reg\n",
        "    @property\n",
        "    def is_multi(self): return self.trn_ds.is_multi\n",
        "    @property\n",
        "    def trn_ds(self): return self.trn_dl.dataset\n",
        "    @property\n",
        "    def val_ds(self): return self.val_dl.dataset\n",
        "    @property\n",
        "    def test_ds(self): return self.test_dl.dataset\n",
        "    @property\n",
        "    def trn_y(self): return self.trn_ds.y\n",
        "    @property\n",
        "    def val_y(self): return self.val_ds.y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "ypfL5bWry7M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_data = ModelData(SAMPLE_DATA_PATH, trn_dl=train_iter_tuple, val_dl=val_iter_tuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Lou0dy4Gy7NF",
        "colab_type": "text"
      },
      "source": [
        "### 1.5. Processed dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Gf3gG8vLy7NG",
        "colab_type": "text"
      },
      "source": [
        "Finally, we are done with processing the dataset: pre-processing, numericalizing, batching and padding.\n",
        "\n",
        "Lets take a look at the final processed data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "RyvEVxWsy7NH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f03128b6-d7c6-421a-9cc8-4eb6ffaa871b"
      },
      "source": [
        "#number of batches in training & validation set and number of tokens in vocabulary\n",
        "len(model_data.trn_dl), len(model_data.val_dl), len(TEXT.vocab)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1250, 197, 52221)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "k0Y4vVmcy7NL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1ae6aa10-303d-464b-eb8c-2f78ba78fb0b"
      },
      "source": [
        "#shape of one batch in training set (sequence_length x batch_size)\n",
        "t, z = next(model_data.trn_dl.__iter__())\n",
        "t.size(), z.size()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([56, 64]), torch.Size([19, 64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "acrmtdk8y7NO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "347683b4-b23d-40af-dda3-04cf9151fe9c"
      },
      "source": [
        "#lets look at an example pair\n",
        "sample_source = t.transpose(1,0)[0].data.cpu().numpy()\n",
        "sample_target = z.transpose(1,0)[0].data.cpu().numpy()\n",
        "\n",
        "print(\"source:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(' '.join([TEXT.vocab.itos[o] for o in sample_source]), sample_source))\n",
        "print(\"target:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(' '.join([TEXT.vocab.itos[o] for o in sample_target]), sample_target))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\n",
            "the death toll from a gas explosion that destroyed a building housing an ice cream factory and apartments in eastern pakistan rose to # # on wednesday as authorities ended their # # -hour rescue operation , police said . _eos_ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
            "\n",
            "corresponding tensor:\n",
            "[  4 202 857  21 ...   1   1   1   1] \n",
            "\n",
            "target:\n",
            "pakistan death toll from gas explosion at building housing ice cream factory rises to # # _eos_ <pad> <pad> \n",
            "\n",
            "corresponding tensor:\n",
            "[ 193  202  857   21  444  897   18  715 1383 2131 9691 2129 1119    7    3    3    2    1    1] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwJoMJhy7NS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK9tNFB9y7NT",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Define model architecture\n",
        "The sequence model, consists of:\n",
        "* single layer encoder-decoder RNNs (biGRU-to-uniGRU)\n",
        "* feed-forward attention network (bahdanau)\n",
        "* option for luong global dot attention\n",
        "* option for teacher forcing\n",
        "* option for tied embeddings\n",
        "* option for multi-layer model\n",
        "* option for regularization (dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfVX6NEy7NT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYx31yaBy7NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, rnn_type, input_size, embz_size, hidden_size, batch_size,output_size,max_tgt_len,\n",
        "                 attention_type, tied_weight_type, pre_trained_vector, pre_trained_vector_type, padding_idx,\n",
        "                 num_layers=1, encoder_drop=(0.0,0.0), decoder_drop=(0.0,0.0), \n",
        "                 bidirectional=True, bias=False, teacher_forcing=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        rnn_type, attention_type, tied_weight_type = rnn_type.upper(), attention_type.title(), tied_weight_type.lower()\n",
        "        \n",
        "        if rnn_type in ['LSTM', 'GRU']: self.rnn_type = rnn_type\n",
        "        else: raise ValueError(\"\"\"An invalid option for '--rnn_type' was supplied,\n",
        "                                    options are ['LSTM', 'GRU']\"\"\")\n",
        "            \n",
        "        if attention_type in ['Luong', 'Bahdanau']: self.attention_type = attention_type\n",
        "        else: raise ValueError(\"\"\"An invalid option for '--attention_type' was supplied,\n",
        "                                    options are ['Luong', 'Bahdanau']\"\"\")\n",
        "            \n",
        "        if tied_weight_type in ['three_way', 'two_way']: self.tied_weight_type = tied_weight_type\n",
        "        else: raise ValueError(\"\"\"An invalid option for '--tied_weight_type' was supplied,\n",
        "                                    options are ['three_way', 'two_way']\"\"\")\n",
        "    \n",
        "                    \n",
        "        #initialize model parameters            \n",
        "        self.output_size, self.embz_size, self.hidden_size = output_size, embz_size, hidden_size//2\n",
        "        self.num_layers, self.input_size, self.max_tgt_len, self.pre_trained_vector = num_layers, input_size, max_tgt_len, pre_trained_vector\n",
        "        self.bidirectional,self.teacher_forcing, self.pre_trained_vector_type = bidirectional, teacher_forcing, pre_trained_vector_type\n",
        "        self.encoder_drop, self.decoder_drop, self.padding_idx = encoder_drop, decoder_drop, padding_idx\n",
        "        \n",
        "        \n",
        "        if self.teacher_forcing: self.force_prob = 1.0\n",
        "        \n",
        "        #set bidirectional\n",
        "        if self.bidirectional: self.num_directions = 2\n",
        "        else: self.num_directions = 1\n",
        "            \n",
        "        \n",
        "        #encoder\n",
        "        self.encoder_dropout = nn.Dropout(self.encoder_drop[0])\n",
        "        self.encoder_embedding_layer = nn.Embedding(self.input_size, self.embz_size, padding_idx=self.padding_idx)\n",
        "        if self.pre_trained_vector: self.encoder_embedding_layer.weight.data.copy_(self.pre_trained_vector.weight.data)\n",
        "            \n",
        "        self.encoder_rnn = getattr(nn, self.rnn_type)(\n",
        "                           input_size=self.embz_size,\n",
        "                           hidden_size=self.hidden_size,\n",
        "                           num_layers=self.num_layers,\n",
        "                           dropout=self.encoder_drop[1], \n",
        "                           bidirectional=self.bidirectional)\n",
        "        self.encoder_vector_layer = nn.Linear(self.hidden_size*self.num_directions,self.embz_size, bias=bias)\n",
        "        \n",
        "       #decoder\n",
        "        self.decoder_dropout = nn.Dropout(self.decoder_drop[0])\n",
        "        self.decoder_embedding_layer = nn.Embedding(self.input_size, self.embz_size, padding_idx=self.padding_idx)\n",
        "        self.decoder_rnn = getattr(nn, self.rnn_type)(\n",
        "                           input_size=self.embz_size,\n",
        "                           hidden_size=self.hidden_size*self.num_directions,\n",
        "                           num_layers=self.num_layers,\n",
        "                           dropout=self.decoder_drop[1]) \n",
        "        self.decoder_output_layer = nn.Linear(self.hidden_size*self.num_directions, self.embz_size, bias=bias)\n",
        "        self.output_layer = nn.Linear(self.embz_size, self.output_size, bias=bias)\n",
        "        \n",
        "        #set tied weights: three way tied weights vs two way tied weights\n",
        "        if self.tied_weight_type == 'three_way':\n",
        "            self.decoder_embedding_layer.weight  = self.encoder_embedding_layer.weight\n",
        "            self.output_layer.weight = self.decoder_embedding_layer.weight  \n",
        "        else:\n",
        "            if self.pre_trained_vector: self.decoder_embedding_layer.weight.data.copy_(self.pre_trained_vector.weight.data)\n",
        "            self.output_layer.weight = self.decoder_embedding_layer.weight  \n",
        "            \n",
        "        #set attention\n",
        "        self.encoder_output_layer = nn.Linear(self.hidden_size*self.num_directions, self.embz_size, bias=bias)\n",
        "        self.att_vector_layer = nn.Linear(self.embz_size+self.embz_size, self.embz_size,bias=bias)\n",
        "        if self.attention_type == 'Bahdanau':\n",
        "            self.decoder_hidden_layer = nn.Linear(self.hidden_size*self.num_directions, self.embz_size, bias=bias)\n",
        "            self.att_score = nn.Linear(self.embz_size,1,bias=bias)\n",
        "\n",
        "            \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (V(torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size)),\n",
        "                    V(torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size)))\n",
        "        else:\n",
        "            return V(torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size))\n",
        "   \n",
        "\n",
        "    def _cat_directions(self, hidden):\n",
        "        def _cat(h):\n",
        "            return torch.cat([h[0:h.size(0):2], h[1:h.size(0):2]], 2)\n",
        "            \n",
        "        if isinstance(hidden, tuple):\n",
        "            # LSTM hidden contains a tuple (hidden state, cell state)\n",
        "            hidden = tuple([_cat(h) for h in hidden])\n",
        "        else:\n",
        "            # GRU hidden\n",
        "            hidden = _cat(hidden)\n",
        "        return hidden    \n",
        "    \n",
        "    \n",
        "    def bahdanau_attention(self, encoder_output, decoder_hidden, decoder_input):\n",
        "        encoder_output = self.encoder_output_layer(encoder_output) \n",
        "        encoder_output = encoder_output.transpose(0,1)\n",
        "        decoder_hidden = decoder_hidden.transpose(0,1)\n",
        "        att_score = F.tanh(encoder_output + decoder_hidden)\n",
        "        att_score = self.att_score(att_score)\n",
        "        att_weight = F.softmax(att_score, dim=1)\n",
        "        context_vector = torch.bmm(att_weight.transpose(-1, 1), encoder_output).squeeze(1)\n",
        "        att_vector = torch.cat((context_vector, decoder_input), dim=1)\n",
        "        att_vector = self.att_vector_layer(att_vector)\n",
        "        return att_weight.squeeze(-1), att_vector\n",
        "    \n",
        "    \n",
        "    def luong_attention(self, encoder_output, decoder_output):\n",
        "        encoder_output = self.encoder_output_layer(encoder_output) \n",
        "        encoder_output = encoder_output.transpose(0,1)\n",
        "        decoder_output = decoder_output.transpose(0,1)\n",
        "        att_score = torch.bmm(encoder_output, decoder_output.transpose(-1,1))\n",
        "        att_weight = F.softmax(att_score, dim=1)\n",
        "        context_vector = torch.bmm(att_weight.transpose(-1, 1), encoder_output).squeeze(1)\n",
        "        att_vector = torch.cat((context_vector, decoder_output.squeeze(1)), dim=1)\n",
        "        att_vector = self.att_vector_layer(att_vector)\n",
        "        att_vector = F.tanh(att_vector)\n",
        "        return att_weight.squeeze(-1), att_vector\n",
        "        \n",
        "    def decoder_forward(self, batch_size, encoder_output, decoder_hidden, y=None):\n",
        "        decoder_input = V(torch.zeros(batch_size).long())  \n",
        "        output_seq_stack, att_stack = [], []\n",
        "        \n",
        "        for i in range(self.max_tgt_len):\n",
        "            decoder_input = self.decoder_dropout(self.decoder_embedding_layer(decoder_input))\n",
        "            if self.attention_type == 'Bahdanau':\n",
        "                if isinstance(decoder_hidden, tuple):\n",
        "                    prev_hidden = self.decoder_hidden_layer(decoder_hidden[0][-1]).unsqueeze(0)\n",
        "                else:\n",
        "                    prev_hidden = self.decoder_hidden_layer(decoder_hidden[-1]).unsqueeze(0) \n",
        "                att, decoder_input = self.bahdanau_attention(encoder_output, prev_hidden, decoder_input)\n",
        "                decoder_output, decoder_hidden = self.decoder_rnn(decoder_input.unsqueeze(0), decoder_hidden)\n",
        "                decoder_output = self.decoder_output_layer(decoder_output.squeeze(0)) \n",
        "            else:\n",
        "                decoder_output, decoder_hidden = self.decoder_rnn(decoder_input.unsqueeze(0), decoder_hidden)\n",
        "                decoder_output = self.decoder_output_layer(decoder_output) \n",
        "                att, decoder_output = self.luong_attention(encoder_output, decoder_output)\n",
        "            att_stack.append(att)\n",
        "            output = self.output_layer(decoder_output)\n",
        "            output_seq_stack.append(output)\n",
        "            decoder_input = V(output.data.max(1)[1])\n",
        "            if (decoder_input==1).all(): break \n",
        "            if self.teacher_forcing:    \n",
        "                samp_prob = round(random.random(),1)\n",
        "                if (y is not None) and (samp_prob < self.force_prob):\n",
        "                    if i >= len(y): break\n",
        "                    decoder_input = y[i] \n",
        "                \n",
        "        return torch.stack(output_seq_stack), torch.stack(att_stack)\n",
        "        \n",
        "                \n",
        "    def forward(self, seq, y=None):\n",
        "        batch_size = seq[0].size(0)\n",
        "        encoder_hidden = self.init_hidden(batch_size)\n",
        "        encoder_input = self.encoder_dropout(self.encoder_embedding_layer(seq))\n",
        "        encoder_output, encoder_hidden = self.encoder_rnn(encoder_input, encoder_hidden) \n",
        "        if self.bidirectional:\n",
        "            encoder_hidden = self._cat_directions(encoder_hidden)\n",
        "        output = self.decoder_forward(batch_size, encoder_output, encoder_hidden, y=y)\n",
        "        if isinstance(encoder_hidden, tuple):\n",
        "            encoder_vector = self.encoder_vector_layer(encoder_hidden[0][-1])\n",
        "        else:\n",
        "            encoder_vector = self.encoder_vector_layer(encoder_hidden[-1])\n",
        "        output = output + (encoder_vector,)  \n",
        "        return output\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMSJWXyVy7Nb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "09b0955a-31b0-4126-a1b2-5d20967ea56b"
      },
      "source": [
        "#set maximum target summary size \n",
        "its = [next(model_data.trn_dl.__iter__())[1] for i in range(10)]\n",
        "max_tgt_len = int(np.percentile([its[o].size()[0] for o in range(len(its))], 99))\n",
        "max_tgt_len"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd7UmiVhy7Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_pickle(path, filename, file):\n",
        "    \"\"\"Function to save file as pickle\"\"\"\n",
        "    with open(f'{path}/{filename}', 'wb') as f:\n",
        "        pickle.dump(file, f)\n",
        "\n",
        "        \n",
        "def norm_pre_trained_embeddings(vecs, itos, em_sz, padding_idx):\n",
        "    \"\"\"Function to load and normalize pretrained vectors\"\"\"\n",
        "    emb = nn.Embedding(len(itos), em_sz, padding_idx=padding_idx)\n",
        "    wgts = emb.weight.data\n",
        "    for i,w in enumerate(itos):\n",
        "        try: \n",
        "            wgts[i] = torch.from_numpy(vecs[w]-vec_mean)\n",
        "            wgts[i] = torch.from_numpy(vecs[w]/vec_std)\n",
        "        except: pass \n",
        "    emb.weight.requires_grad = False    \n",
        "    return emb\n",
        "\n",
        "\n",
        "def embedding_param(path, data_field, pre_trained_vector_type, embz_size=128, save_vocab=False, itos='itos', stoi='stoi'):\n",
        "    \"\"\"Returns embedding parameters\"\"\"\n",
        "    pre_trained=None\n",
        "    padding_idx = data_field.vocab.stoi['<pad>']\n",
        "    index_to_string, string_to_index = data_field.vocab.itos, data_field.vocab.stoi\n",
        "    if save_vocab:\n",
        "        vocab_path = os.path.join(path, \"vocab\")\n",
        "        os.makedirs(vocab_path, exist_ok=True)\n",
        "        save_pickle(vocab_path, f'{itos}.pk', index_to_string) \n",
        "        save_pickle(vocab_path, f'{stoi}.pk', string_to_index) \n",
        "    if pre_trained_vector_type:\n",
        "        vec_mean, vec_std = data_field.vocab.vectors.numpy().mean(), data_field.vocab.vectors.numpy().std()\n",
        "        print('pre_trained_vector_mean = %s, pre_trained_vector_std = %s'%(vec_mean, vec_std))\n",
        "        vector_weight_matrix = data_field.vocab.vectors\n",
        "        embz_size = vector_weight_matrix.size(1)\n",
        "        pre_trained = norm_pre_trained_embeddings(vector_weight_matrix, index_to_string, embz_size, padding_idx)\n",
        "        print('Normalizing.... \\npre_trained_vector_mean = %s, pre_trained_vector_std = %s' %(pre_trained.weight.data.numpy().mean(), pre_trained.weight.data.numpy().std()))\n",
        "    return pre_trained, embz_size, padding_idx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX7zbUrYy7Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9d98b7ce-46eb-4a20-e5dd-68ca5f3c8f13"
      },
      "source": [
        "rev=0\n",
        "rev += 1\n",
        "print(\"rev = %s\" %rev)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rev = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzb2LLYXy7Nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "98126783-04a1-44b1-9bf4-32b1517c51e0"
      },
      "source": [
        "pre_trained_vector,  embz_size, padding_idx = embedding_param(SAMPLE_DATA_PATH, TEXT, pre_trained_vector_type, save_vocab=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pre_trained_vector_mean = 0.0019917963, pre_trained_vector_std = 0.43600857\n",
            "Normalizing.... \n",
            "pre_trained_vector_mean = 0.00047053993, pre_trained_vector_std = 1.0001359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWP2Vlzby7Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = len(TEXT.vocab)\n",
        "hidden_size = 400\n",
        "output_size =  len(TEXT.vocab)\n",
        "rnn_type = 'gru'\n",
        "tied_weight_type ='three_way'\n",
        "max_tgt_len = max_tgt_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbycPRhWy7N2",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4_P1zQy7N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Stepper():\n",
        "    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n",
        "        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n",
        "        self.fp16 = fp16\n",
        "        self.reset(True)\n",
        "        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n",
        "        self.loss_scale = loss_scale\n",
        "\n",
        "    def reset(self, train=True):\n",
        "        if train: apply_leaf(self.m, set_train_mode)\n",
        "        else: self.m.eval()\n",
        "        if hasattr(self.m, 'reset'):\n",
        "            self.m.reset()\n",
        "            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n",
        "\n",
        "    def step(self, xs, y, epoch):\n",
        "        xtra = []\n",
        "        output = self.m(*xs)\n",
        "        if isinstance(output,tuple): output,*xtra = output\n",
        "        if self.fp16: self.m.zero_grad()\n",
        "        else: self.opt.zero_grad() \n",
        "        loss = raw_loss = self.crit(output, y)\n",
        "        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n",
        "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
        "        loss.backward()\n",
        "        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n",
        "        if self.loss_scale != 1:\n",
        "            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n",
        "        if self.clip:   # Gradient clipping\n",
        "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
        "        self.opt.step()\n",
        "        if self.fp16: \n",
        "            copy_fp32_toStepper_model(self.m, self.fp32_params)\n",
        "            torch.cuda.synchronize()\n",
        "        return torch_item(raw_loss.data)\n",
        "\n",
        "    def evaluate(self, xs, y):\n",
        "        preds = self.m(*xs)\n",
        "        if isinstance(preds,tuple): preds=preds[0]\n",
        "        return preds, self.crit(preds, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ETFYS_9Teuu2",
        "colab": {},
        "outputId": "46a24ac1-e0eb-45f8-e999-547af31d3490"
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBUlaEvzy7N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdFjvuN8y7OB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691081d3-1dae-4491-cac9-9a930502cdcd"
      },
      "source": [
        "#custom callbacks\n",
        "from tensorboardX import SummaryWriter\n",
        "from fastai.sgdr import Callback, DecayScheduler\n",
        "from fastai.learner import Learner\n",
        "\n",
        "class TensorboardLogger(Callback):\n",
        "    def __init__(self, path, log_name, metrics_names=[]):\n",
        "        super().__init__()\n",
        "        self.metrics_names = [\"validation_loss\"]\n",
        "        self.metrics_names += metrics_names\n",
        "        log_path = os.path.join(path, \"logs\")\n",
        "        self.log_dir = os.path.join(log_path, log_name)\n",
        "        if os.path.exists(self.log_dir): shutil.rmtree(self.log_dir)\n",
        "        os.makedirs(self.log_dir)\n",
        "        \n",
        "    def on_train_begin(self):\n",
        "        self.iteration = 0\n",
        "        self.epoch = 0\n",
        "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
        "    def on_batch_begin(self): pass\n",
        "    def on_phase_begin(self): pass\n",
        "    def on_epoch_end(self, metrics):\n",
        "        self.epoch += 1\n",
        "        for val, name in zip(metrics, self.metrics_names):\n",
        "            self.writer.add_scalar(name, val, self.iteration) \n",
        "                        \n",
        "    def on_phase_end(self): pass\n",
        "    def on_batch_end(self, loss):\n",
        "        self.iteration += 1\n",
        "        self.writer.add_scalar(\"training_loss\", loss, self.iteration)\n",
        "    def on_train_end(self):\n",
        "        self.writer.close()\n",
        "        \n",
        "        \n",
        "class BestModelCheckPoint(Callback):\n",
        "    def __init__(self, learner, path, model_name, lr):\n",
        "        super().__init__()\n",
        "        self.learner = learner\n",
        "        self.model_name = model_name\n",
        "        self.learning_rate = lr\n",
        "        self.model_log = {}\n",
        "        self.model_path = self.learner.models_path\n",
        "        os.makedirs(self.model_path, exist_ok=True)\n",
        "\n",
        "    def on_train_begin(self): \n",
        "        self.first_epoch = True\n",
        "        self.epoch = 0\n",
        "        self.best_loss = 0.\n",
        "\n",
        "    def on_batch_begin(self): pass\n",
        "    def on_phase_begin(self): pass\n",
        "    def on_epoch_end(self, metrics): \n",
        "        self.epoch += 1\n",
        "        self.val_loss = metrics[0]\n",
        "        if self.first_epoch:\n",
        "            self.best_loss = self.val_loss\n",
        "            self.first_epoch = False\n",
        "        elif self.val_loss < self.best_loss:\n",
        "            self.best_loss = self.val_loss\n",
        "            self.learner.save(self.model_name)\n",
        "            self.model_log['training_loss'] = [str(self.train_losses)]\n",
        "            self.model_log['validation_loss'] = [str(self.val_loss)]\n",
        "            self.model_log['epoch_num'] = [str(self.epoch)]\n",
        "            self.model_log['learning_rate'] = [str(self.learning_rate)]\n",
        "            self.model_log['model_info'] = [w for s in [str(self.learner.model)] for w in s.split('\\n')]\n",
        "            self.model_log['model_info'].append(\"(attention_type): %s\" %self.learner.model.attention_type)\n",
        "            self.model_log['model_info'].append(\"(weight_tie): %s\" %self.learner.model.tied_weight_type)\n",
        "            self.model_log['model_info'].append(\"(pre_trained_vector_type): %s\" %self.learner.model.pre_trained_vector_type)\n",
        "            self.model_log['model_info'].append(\"(teacher_forcing): %s\" %self.learner.model.teacher_forcing)\n",
        "            if self.learner.model.teacher_forcing: self.model_log['model_info'].append(\"(teacher_forcing_prob): %s\" %self.learner.model.force_prob)\n",
        "            with open(f'{self.model_path}/{self.model_name}_model_log.json', 'w') as d: json.dump(self.model_log, d)\n",
        "        else: pass        \n",
        "    def on_phase_end(self): pass\n",
        "    def on_batch_end(self, loss):\n",
        "        self.train_losses = loss\n",
        "    def on_train_end(self): \n",
        "            self.learner.save(f'{self.model_name}_train_end')\n",
        "            self.model_log['training_loss'] = [str(self.train_losses)]\n",
        "            self.model_log['validation_loss'] = [str(self.val_loss)]\n",
        "            self.model_log['epoch_num'] = [str(self.epoch)]\n",
        "            self.model_log['learning_rate'] = [str(self.learning_rate)]\n",
        "            self.model_log['model_info'] = [w for s in [str(self.learner.model)] for w in s.split('\\n')]\n",
        "            self.model_log['model_info'].append(\"(attention_type): %s\" %self.learner.model.attention_type)\n",
        "            self.model_log['model_info'].append(\"(weight_tie): %s\" %self.learner.model.tied_weight_type)\n",
        "            self.model_log['model_info'].append(\"(pre_trained_vector_type): %s\" %self.learner.model.pre_trained_vector_type)\n",
        "            self.model_log['model_info'].append(\"(teacher_forcing): %s\" %self.learner.model.teacher_forcing)\n",
        "            if self.learner.model.teacher_forcing: self.model_log['model_info'].append(\"(teacher_forcing_prob): %s\" %self.learner.model.force_prob)\n",
        "            with open(f'{self.model_path}/{self.model_name}_train_end_model_log.json', 'w') as d: json.dump(self.model_log, d)\n",
        "\n",
        "class TeacherForcingSched(Callback):\n",
        "    def __init__(self, learner, scheduler):\n",
        "        super().__init__()\n",
        "        self.learner = learner\n",
        "        self.scheduler = scheduler\n",
        "        \n",
        "    def on_train_begin(self): \n",
        "        self.learner.model.force_prob = round(self.scheduler.next_val(),1)\n",
        "        \n",
        "    def on_batch_begin(self): pass\n",
        "    def on_phase_begin(self): pass\n",
        "    def on_epoch_end(self, metrics): \n",
        "        self.learner.model.force_prob = round(self.scheduler.next_val(),1)\n",
        "        \n",
        "    def on_phase_end(self): pass\n",
        "    def on_batch_end(self, loss):pass\n",
        "    def on_train_end(self): pass\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-56a245159f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgdr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecayScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTensorboardLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.sgdr'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cJAZVC4y7OG",
        "colab_type": "code",
        "colab": {},
        "outputId": "eb2ef4b6-3d61-44ca-cad5-33149df3a907"
      },
      "source": [
        "attention_type='luong'\n",
        "model_luong = Seq2SeqRNN(rnn_type, input_size, embz_size, hidden_size, batch_size, output_size, max_tgt_len,\n",
        "               attention_type, tied_weight_type, pre_trained_vector, pre_trained_vector_type, padding_idx)\n",
        "\n",
        "print('='*100)\n",
        "print('Model log:')\n",
        "print(model_luong, '\\n')\n",
        "print('- attention_type = {} \\n'.format(model_luong.attention_type))\n",
        "print('- weight_tie = {} \\n'.format(model_luong.tied_weight_type))\n",
        "print('- teacher_forcing = {} \\n '.format(model_luong.teacher_forcing)) \n",
        "print('- pre_trained_embedding = {} \\n'.format(model_luong.pre_trained_vector_type)) \n",
        "print('='*100 + '\\n')\n",
        "\n",
        "if USE_GPU:\n",
        "    model_luong.cuda()\n",
        "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
        "learn_luong = RNN_Learner(model_data, SingleModel(model_luong), opt_fn=opt_fn)\n",
        "learn.crit = seq2seq_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSbicbE_y7OM",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2e0c3eb-a772-4470-aa2d-c090272886ea"
      },
      "source": [
        "learn_luong.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_ywZvf3Ky7OQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "5401f4c1-ba51-49d6-fa11-df55eac6fc9a"
      },
      "source": [
        "learn_luong.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8CS6pRQy7OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7waXZBNy7OW",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e94bfc5-e534-407f-a16a-f3ae9e27be45"
      },
      "source": [
        "# Luong Attention model\n",
        "lr=1e-3\n",
        "model_name = f'{model_luong.rnn_type}_{model_luong.attention_type}_rev_{rev}'.lower()\n",
        "cycle_len=15\n",
        "best_model = BestModelCheckPoint(learn_luong, model_data.path, model_name, lr)\n",
        "tb_logger = TensorboardLogger(model_data.path, model_name)\n",
        "sched = DecayScheduler(DecayType.LINEAR, cycle_len, 0.5, 0.1)\n",
        "teach_forcer = TeacherForcingSched(learn_luong, sched)\n",
        "learn_luong.fit(lr, 1, cycle_len=cycle_len, use_clr=(20,10), stepper=Seq2SeqStepper, \\\n",
        "          callbacks=[tb_logger, teach_forcer, best_model])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UIlCp_5y7OZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "806a13ac-5010-4c9a-f4df-33721d22d584"
      },
      "source": [
        "attention_type='bahdanau'\n",
        "model_bahdanau = Seq2SeqRNN(rnn_type, input_size, embz_size, hidden_size, batch_size, output_size, max_tgt_len,\n",
        "               attention_type, tied_weight_type, pre_trained_vector, pre_trained_vector_type, padding_idx)\n",
        "\n",
        "print('='*100)\n",
        "print('Model log:')\n",
        "print(model_bahdanau, '\\n')\n",
        "print('- attention_type = {} \\n'.format(model_bahdanau.attention_type))\n",
        "print('- weight_tie = {} \\n'.format(model_bahdanau.tied_weight_type))\n",
        "print('- teacher_forcing = {} \\n '.format(model_bahdanau.teacher_forcing)) \n",
        "print('- pre_trained_embedding = {} \\n'.format(model_bahdanau.pre_trained_vector_type)) \n",
        "print('='*100 + '\\n')\n",
        "\n",
        "if USE_GPU:\n",
        "    model_bahdanau.cuda()\n",
        "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
        "learn_luong = RNN_Learner(model_data, SingleModel(model_bahdanau), opt_fn=opt_fn)\n",
        "learn.crit = seq2seq_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mL2tKNOqy7Oc",
        "colab_type": "code",
        "colab": {},
        "outputId": "16a9290c-9fb0-4a4a-94f8-c01a5f90fc69"
      },
      "source": [
        "# Bahdanau Attention Model\n",
        "lr=1e-3\n",
        "model_name = f'{model.rnn_type}_{model.attention_type}_rev_{rev}'.lower()\n",
        "cycle_len=15\n",
        "best_model = BestModelCheckPoint(learn, model_data.path, model_name, lr)\n",
        "tb_logger = TensorboardLogger(model_data.path, model_name)\n",
        "sched = DecayScheduler(DecayType.LINEAR, cycle_len, 0.5, 0.1)\n",
        "teach_forcer = TeacherForcingSched(learn, sched)\n",
        "learn.fit(lr, 1, cycle_len=cycle_len, use_clr=(20,10), stepper=Seq2SeqStepper, \\\n",
        "          callbacks=[tb_logger, teach_forcer, best_model])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmXlswv1y7Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "c8czqvosy7Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def generate(x, y, m):\n",
        "    probs = m.model(V(x))\n",
        "    preds, attention, encoder_embedding = to_np(probs[0].max(2)[1]), to_np(probs[1].squeeze(1)), to_np(probs[2])\n",
        "    sentence = ' '.join([index_to_string[o] for o in x[:,0].data.cpu().numpy() if o != 1])\n",
        "    result = ' '.join([index_to_string[o] for o in preds[:,0] if o!=1])\n",
        "    orig = ' '.join([index_to_string[o] for o in y[:,0].data.cpu().numpy() if o != 1])\n",
        "    print('Input: {}'.format(sentence), '\\n')\n",
        "    print('Original summary: {}'.format(orig), '\\n')\n",
        "    print('Predicted summary: {}'.format(result))\n",
        "    attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "    return preds, attention, encoder_embedding\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zndt-uuwy7Ox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a75705-3d1f-46ce-c256-a94526e3d93e"
      },
      "source": [
        "attention_type='luong'\n",
        "model_luong = Seq2SeqRNN(rnn_type, input_size, embz_size, hidden_size, batch_size, output_size, max_tgt_len,\n",
        "               attention_type, tied_weight_type, pre_trained_vector, pre_trained_vector_type, padding_idx)\n",
        "if USE_GPU:\n",
        "    model_luong.cuda()\n",
        "learn_luong = RNN_Learner(model_data, SingleModel(model_luong))\n",
        "learn_luong.load('gru_luong_rev_1_train_end')\n",
        "\n",
        "attention_type='bahdanau'\n",
        "model_bahdanau = Seq2SeqRNN(rnn_type, input_size, embz_size, hidden_size, batch_size, output_size, max_tgt_len,\n",
        "               attention_type, tied_weight_type, pre_trained_vector, pre_trained_vector_type, padding_idx)\n",
        "if USE_GPU:\n",
        "    model_bahdanau.cuda()\n",
        "learn_bahdanau = RNN_Learner(model_data, SingleModel(model_bahdanau))\n",
        "learn_bahdanau.load('gru_bahdanau_rev_1_train_end')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3a5d30793a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_GPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_luong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlearn_luong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_luong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlearn_luong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gru_luong_rev_1_train_end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RNN_Learner' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "J79HRQfby7O0",
        "colab_type": "code",
        "colab": {},
        "outputId": "247625b7-cba2-447b-f957-27933d0e3753"
      },
      "source": [
        "# Luong (Global Dot) Attention\n",
        "x,y = next(iter(model_data.trn_dl))\n",
        "for i in range(1):\n",
        "    print(i)\n",
        "    preds, attention, encoder_embedding = generate(x.transpose(1,0)[i].unsqueeze(1), y.transpose(1,0)[i].unsqueeze(1), learn_luong)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0Exc4Lthy7O4",
        "colab_type": "code",
        "colab": {},
        "outputId": "8c30d994-325e-46ca-c597-bfe12d1db1ae"
      },
      "source": [
        "# Bahdanau Attention\n",
        "for i in range(1):\n",
        "    print(i)\n",
        "    preds, attention, encoder_embedding = generate(x.transpose(1,0)[i].unsqueeze(1), y.transpose(1,0)[i].unsqueeze(1), learn_bahdanau)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}